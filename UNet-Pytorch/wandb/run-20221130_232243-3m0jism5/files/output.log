INFO: Starting training:
        Epochs:          2
        Batch size:      3
        Learning rate:   1e-05
        Training size:   65280
        Validation size: 8160
        Checkpoints:     True
        Device:          cpu
        Images scaling:  1
        Mixed Precision: False








































































Epoch 1/2:   0%|â–Ž                                                                  | 315/65280 [02:28<8:29:44,  2.12img/s, loss (batch)=0.567]
INFO: Saved interrupt
Traceback (most recent call last):
  File "/home/hewei/TUM/ADLR/tum-adlr-8/UNet-Pytorch/train.py", line 202, in <module>
    train_net(net=net,
  File "/home/hewei/TUM/ADLR/tum-adlr-8/UNet-Pytorch/train.py", line 112, in train_net
    grad_scaler.scale(loss).backward()
  File "/home/hewei/miniconda3/envs/i2dl/lib/python3.10/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/hewei/miniconda3/envs/i2dl/lib/python3.10/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt